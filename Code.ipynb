{"cells":[{"cell_type":"markdown","metadata":{"id":"J7WWYL00bWbx"},"source":["## Code used to train the U-Net model on EM Cell Segmentation Challenge - ISBI 2012"]},{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4137,"status":"ok","timestamp":1607868600732,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"-fMTR8dbkQkT","outputId":"979ed7cb-ce99-4291-da38-546f2a663ab0"},"outputs":[],"source":["from PIL import Image\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K\n","from albumentations import Transpose,RandomRotate90, GridDistortion, HorizontalFlip, VerticalFlip, ElasticTransform\n","\n","from skimage.io import imshow\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","%load_ext tensorboard\n","import datetime\n","\n","import cv2"]},{"cell_type":"markdown","metadata":{},"source":["### Function to input multipage tif file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gpspsyieXK4"},"outputs":[],"source":["\n","def read_tiff(path):\n","    \"\"\"\n","    path - Path to the multipage-tiff file\n","    \"\"\"\n","    img = Image.open(path)\n","    images = []\n","    for i in range(img.n_frames):\n","        img.seek(i)\n","        images.append(np.array(img))\n","    return np.array(images)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3026,"status":"ok","timestamp":1607868552306,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"qQ6mE5JHe_3-","outputId":"d80ea1a3-407f-4687-fcf3-a9c5f964dc3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of train set is (30, 512, 512).\n","The shape of train labels is (30, 512, 512).\n"]}],"source":["X_train = read_tiff('/train-volume.tif')\n","Y_train = read_tiff('/train-labels.tif')\n","\n","#shape check\n","print(\"The shape of train set is {s1}.\\nThe shape of train labels is {s2}.\".format(s1=X_train.shape,s2=Y_train.shape))"]},{"cell_type":"markdown","metadata":{},"source":["### random print to check correct maping of data to labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":5078,"status":"ok","timestamp":1607868566133,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"MHept3NvlvyB","outputId":"bc8b4ba0-df46-4214-d5f4-9d0084843ff5"},"outputs":[],"source":["rand_num = np.random.randint(0,29)\n","print('At Index : {index}'.format(index = rand_num))\n","plt.subplot(121), imshow(X_train[rand_num])\n","plt.title('Train image') \n","\n","plt.subplot(122), imshow(Y_train[rand_num])\n","plt.title('Train label') \n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["#### Random Rotation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VoGzRVnloCGO"},"outputs":[],"source":["finalaugimg = X_train\n","finalaugmask = Y_train\n","\n","rr90imgs = []\n","rr90masks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=RandomRotate90(p=1.0)\n","    augmented = aug(image=x,mask=y)\n","    rr90imgs.append(augmented['image'])\n","    rr90masks.append(augmented['mask'])\n","\n","finalaugimg = np.concatenate([finalaugimg,rr90imgs])\n","finalaugmask = np.concatenate([finalaugmask,rr90masks])\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Grid Distortion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tr-htBZTs3Fs"},"outputs":[],"source":["gdimgs = []\n","gdmasks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=GridDistortion(p=1.0)\n","    augmented = aug(image=x,mask=y)\n","    gdimgs.append(augmented['image'])\n","    gdmasks.append(augmented['mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OS9AskTAtDBS"},"outputs":[],"source":["finalaugimg = np.concatenate([finalaugimg,gdimgs])\n","finalaugmask = np.concatenate([finalaugmask,gdmasks])"]},{"cell_type":"markdown","metadata":{},"source":["#### Horizontal Flip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPK4QXtT4Ie2"},"outputs":[],"source":["hfimgs = []\n","hfmasks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=HorizontalFlip(p=1.0)\n","    augmented = aug(image=x,mask=y)\n","    hfimgs.append(augmented['image'])\n","    hfmasks.append(augmented['mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBQ8HJEZ4IRF"},"outputs":[],"source":["finalaugimg = np.concatenate([finalaugimg,hfimgs])\n","finalaugmask = np.concatenate([finalaugmask,hfmasks])"]},{"cell_type":"markdown","metadata":{},"source":["#### Vertical Flip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ysq2FiDu4IDj"},"outputs":[],"source":["vfimgs = []\n","vfmasks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=VerticalFlip(p=1.0)\n","    augmented = aug(image=x,mask=y)\n","    vfimgs.append(augmented['image'])\n","    vfmasks.append(augmented['mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tU63U33f4HzI"},"outputs":[],"source":["finalaugimg = np.concatenate([finalaugimg,vfimgs])\n","finalaugmask = np.concatenate([finalaugmask,vfmasks])"]},{"cell_type":"markdown","metadata":{},"source":["#### Transpose"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdmgoTkP3o8c"},"outputs":[],"source":["timgs = []\n","tmasks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=Transpose(p=1.0)\n","    augmented = aug(image=x,mask=y)\n","    timgs.append(augmented['image'])\n","    tmasks.append(augmented['mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJHV5dTy34jT"},"outputs":[],"source":["finalaugimg = np.concatenate([finalaugimg,timgs])\n","finalaugmask = np.concatenate([finalaugmask,tmasks])"]},{"cell_type":"markdown","metadata":{},"source":["#### Elastic Transform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEOo7qw-zx6F"},"outputs":[],"source":["etimgs = []\n","etmasks = []\n","\n","for x,y in zip(X_train,Y_train):\n","    aug=ElasticTransform(sigma=10,interpolation=cv2.INTER_CUBIC)\n","    augmented = aug(image=x,mask=y)\n","    etimgs.append(augmented['image'])\n","    etmasks.append(augmented['mask'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjO4Zmrhzxqg"},"outputs":[],"source":["finalaugimg = np.concatenate([finalaugimg,etimgs])\n","finalaugmask = np.concatenate([finalaugmask,etmasks])"]},{"cell_type":"markdown","metadata":{},"source":["### Viewing Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"elapsed":7202,"status":"ok","timestamp":1607868616426,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"CZa4odTt_EfC","outputId":"ead49b5e-6f02-4105-b77d-87260028fba1"},"outputs":[],"source":["finalaugimg.shape,finalaugmask.shape\n","\n","rand_nums = [rand_num,rand_num+30,rand_num+60,rand_num+90,rand_num+120,rand_num+150,rand_num+180]\n","plt.figure(figsize=(20,10))\n","plt.subplot(171), imshow(finalaugimg[rand_nums[0]])\n","plt.title('Original')\n","plt.subplot(172), imshow(finalaugimg[rand_nums[1]])\n","plt.title('Random Rotate 90')\n","plt.subplot(173), imshow(finalaugimg[rand_nums[2]])\n","plt.title('Grid Distortion')\n","plt.subplot(174), imshow(finalaugimg[rand_nums[3]])\n","plt.title('Horizontal Flip')\n","plt.subplot(175), imshow(finalaugimg[rand_nums[4]])\n","plt.title('Vertical Flip')\n","plt.subplot(176), imshow(finalaugimg[rand_nums[5]])\n","plt.title('Transpose')\n","plt.subplot(177), imshow(finalaugimg[rand_nums[6]])\n","plt.title('Elastic Transform')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"elapsed":9487,"status":"ok","timestamp":1607868619619,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"0lo8YMjyOGCg","outputId":"ee966cd2-1387-4080-bcb0-8e18b47bfbd9"},"outputs":[],"source":["plt.figure(figsize=(20,10))\n","plt.subplot(171), imshow(finalaugmask[rand_nums[0]])\n","plt.title('Original')\n","plt.subplot(172), imshow(finalaugmask[rand_nums[1]])\n","plt.title('Random Rotate 90')\n","plt.subplot(173), imshow(finalaugmask[rand_nums[2]])\n","plt.title('Grid Distortion')\n","plt.subplot(174), imshow(finalaugmask[rand_nums[3]])\n","plt.title('Horizontal Flip')\n","plt.subplot(175), imshow(finalaugmask[rand_nums[4]])\n","plt.title('Vertical Flip')\n","plt.subplot(176), imshow(finalaugmask[rand_nums[5]])\n","plt.title('Transpose')\n","plt.subplot(177), imshow(finalaugmask[rand_nums[6]])\n","plt.title('Elastic Transform')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Focal Loss for training model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OU93PsBb-wiU"},"outputs":[],"source":["\n","def focal_loss(gamma=2., alpha=.25):\n","\tdef focal_loss_fixed(y_true, y_pred):\n","\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n","\treturn focal_loss_fixed"]},{"cell_type":"markdown","metadata":{},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6988,"status":"ok","timestamp":1607868638864,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"ZU53LWkkopch","outputId":"63a86ab1-50a8-4d36-af68-5cf1ef26befc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 512, 512, 1)  0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 512, 512, 64) 640         lambda[0][0]                     \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 512, 512, 64) 0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 256, 256, 128 0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 128, 128, 256 0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      dropout_2[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 32, 32, 1024) 0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose (Conv2DTranspo (None, 64, 64, 512)  2097664     conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_transpose[0][0]           \n","                                                                 conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 64, 64, 512)  0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 64, 64, 512)  2359808     dropout_5[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 256 524544      conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_transpose_1[0][0]         \n","                                                                 conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 128, 128, 256 0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 128, 128, 256 590080      dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 128 131200      conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_transpose_2[0][0]         \n","                                                                 conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 256, 256, 128 0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 256, 256, 128 147584      dropout_7[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_transpose_3 (Conv2DTrans (None, 512, 512, 64) 32832       conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_transpose_3[0][0]         \n","                                                                 conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","dropout_8 (Dropout)             (None, 512, 512, 64) 0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 512, 512, 64) 36928       dropout_8[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 512, 512, 1)  65          conv2d_17[0][0]                  \n","==================================================================================================\n","Total params: 31,030,593\n","Trainable params: 31,030,593\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["\n","inputs = tf.keras.layers.Input((512,512,1))\n","float_inputs = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n","\n","c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(float_inputs)\n","c1 = tf.keras.layers.Dropout(0.1)(c1)\n","c1 = tf.keras.layers.Conv2D(64, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","p1 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(c1)\n","\n","c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","c2 = tf.keras.layers.Dropout(0.1)(c2)\n","c2 = tf.keras.layers.Conv2D(128, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","p2 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(c2)\n"," \n","c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","c3 = tf.keras.layers.Dropout(0.2)(c3)\n","c3 = tf.keras.layers.Conv2D(256, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","p3 = tf.keras.layers.MaxPooling2D(pool_size = (2, 2))(c3)\n"," \n","c4 = tf.keras.layers.Conv2D(512,3, activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","c4 = tf.keras.layers.Dropout(0.2)(c4)\n","c4 = tf.keras.layers.Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n"," \n","c5 = tf.keras.layers.Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","c5 = tf.keras.layers.Dropout(0.3)(c5)\n","c5 = tf.keras.layers.Conv2D(1024, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","u6 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n","u6 = tf.keras.layers.concatenate([u6, c4],axis = 3)\n","c6 = tf.keras.layers.Conv2D(512,3, activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","c6 = tf.keras.layers.Dropout(0.2)(c6)\n","c6 = tf.keras.layers.Conv2D(512, 3, activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n"," \n","u7 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n","u7 = tf.keras.layers.concatenate([u7, c3],axis = 3)\n","c7 = tf.keras.layers.Conv2D(256,3, activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","c7 = tf.keras.layers.Dropout(0.2)(c7)\n","c7 = tf.keras.layers.Conv2D(256,3, activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n"," \n","u8 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n","u8 = tf.keras.layers.concatenate([u8, c2],axis = 3)\n","c8 = tf.keras.layers.Conv2D(128,3, activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","c8 = tf.keras.layers.Dropout(0.1)(c8)\n","c8 = tf.keras.layers.Conv2D(128,3, activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n"," \n","u9 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n","u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n","c9 = tf.keras.layers.Conv2D(64,3, activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","c9 = tf.keras.layers.Dropout(0.1)(c9)\n","c9 = tf.keras.layers.Conv2D(64,3, activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n","\n","outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c9)\n"," \n","model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n","model.compile(optimizer='adam', loss=[focal_loss(alpha=.25, gamma=2)], metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2696714,"status":"ok","timestamp":1607698545761,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"VZ07sMk7_O7J","outputId":"96747ec3-97ed-41a1-ccf7-dd1fea93f75b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"," 2/27 [=>............................] - ETA: 25s - loss: 0.1265 - accuracy: 0.4495WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0833s vs `on_train_batch_end` time: 1.9416s). Check your callbacks.\n","27/27 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.7315WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_test_batch_end` time: 0.5652s). Check your callbacks.\n","\n","Epoch 00001: val_loss improved from inf to 0.04505, saving model to focal.h5\n","27/27 [==============================] - 48s 2s/step - loss: 0.0617 - accuracy: 0.7315 - val_loss: 0.0451 - val_accuracy: 0.7937\n","Epoch 2/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.7997\n","Epoch 00002: val_loss improved from 0.04505 to 0.03905, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0443 - accuracy: 0.7997 - val_loss: 0.0391 - val_accuracy: 0.8306\n","Epoch 3/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.8189\n","Epoch 00003: val_loss improved from 0.03905 to 0.03557, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0379 - accuracy: 0.8189 - val_loss: 0.0356 - val_accuracy: 0.8555\n","Epoch 4/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.8319\n","Epoch 00004: val_loss improved from 0.03557 to 0.03516, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0352 - accuracy: 0.8319 - val_loss: 0.0352 - val_accuracy: 0.8721\n","Epoch 5/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.8463\n","Epoch 00005: val_loss improved from 0.03516 to 0.03012, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0319 - accuracy: 0.8463 - val_loss: 0.0301 - val_accuracy: 0.8492\n","Epoch 6/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.8638\n","Epoch 00006: val_loss improved from 0.03012 to 0.02682, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0291 - accuracy: 0.8638 - val_loss: 0.0268 - val_accuracy: 0.8979\n","Epoch 7/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.8759\n","Epoch 00007: val_loss improved from 0.02682 to 0.02654, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0275 - accuracy: 0.8759 - val_loss: 0.0265 - val_accuracy: 0.8754\n","Epoch 8/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.8711\n","Epoch 00008: val_loss did not improve from 0.02654\n","27/27 [==============================] - 45s 2s/step - loss: 0.0284 - accuracy: 0.8711 - val_loss: 0.0268 - val_accuracy: 0.8968\n","Epoch 9/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.8773\n","Epoch 00009: val_loss improved from 0.02654 to 0.02584, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0264 - accuracy: 0.8773 - val_loss: 0.0258 - val_accuracy: 0.8742\n","Epoch 10/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.8841\n","Epoch 00010: val_loss improved from 0.02584 to 0.02438, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0255 - accuracy: 0.8841 - val_loss: 0.0244 - val_accuracy: 0.8890\n","Epoch 11/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.8868\n","Epoch 00011: val_loss improved from 0.02438 to 0.02333, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0248 - accuracy: 0.8868 - val_loss: 0.0233 - val_accuracy: 0.8918\n","Epoch 12/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.8878\n","Epoch 00012: val_loss improved from 0.02333 to 0.02325, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0244 - accuracy: 0.8878 - val_loss: 0.0232 - val_accuracy: 0.8945\n","Epoch 13/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.8897\n","Epoch 00013: val_loss improved from 0.02325 to 0.02184, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0238 - accuracy: 0.8897 - val_loss: 0.0218 - val_accuracy: 0.9027\n","Epoch 14/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.8927\n","Epoch 00014: val_loss did not improve from 0.02184\n","27/27 [==============================] - 44s 2s/step - loss: 0.0233 - accuracy: 0.8927 - val_loss: 0.0229 - val_accuracy: 0.8938\n","Epoch 15/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.8893\n","Epoch 00015: val_loss did not improve from 0.02184\n","27/27 [==============================] - 44s 2s/step - loss: 0.0239 - accuracy: 0.8893 - val_loss: 0.0224 - val_accuracy: 0.9085\n","Epoch 16/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.8939\n","Epoch 00016: val_loss improved from 0.02184 to 0.02129, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0228 - accuracy: 0.8939 - val_loss: 0.0213 - val_accuracy: 0.9088\n","Epoch 17/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.8947\n","Epoch 00017: val_loss improved from 0.02129 to 0.02120, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0225 - accuracy: 0.8947 - val_loss: 0.0212 - val_accuracy: 0.9109\n","Epoch 18/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.8964\n","Epoch 00018: val_loss improved from 0.02120 to 0.02009, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0219 - accuracy: 0.8964 - val_loss: 0.0201 - val_accuracy: 0.9075\n","Epoch 19/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.8982\n","Epoch 00019: val_loss improved from 0.02009 to 0.01977, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0216 - accuracy: 0.8982 - val_loss: 0.0198 - val_accuracy: 0.9104\n","Epoch 20/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.8980\n","Epoch 00020: val_loss did not improve from 0.01977\n","27/27 [==============================] - 44s 2s/step - loss: 0.0214 - accuracy: 0.8980 - val_loss: 0.0198 - val_accuracy: 0.9144\n","Epoch 21/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9001\n","Epoch 00021: val_loss improved from 0.01977 to 0.01914, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0212 - accuracy: 0.9001 - val_loss: 0.0191 - val_accuracy: 0.9132\n","Epoch 22/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9003\n","Epoch 00022: val_loss did not improve from 0.01914\n","27/27 [==============================] - 44s 2s/step - loss: 0.0209 - accuracy: 0.9003 - val_loss: 0.0202 - val_accuracy: 0.9187\n","Epoch 23/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.8996\n","Epoch 00023: val_loss did not improve from 0.01914\n","27/27 [==============================] - 44s 2s/step - loss: 0.0212 - accuracy: 0.8996 - val_loss: 0.0192 - val_accuracy: 0.9120\n","Epoch 24/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9008\n","Epoch 00024: val_loss improved from 0.01914 to 0.01871, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0206 - accuracy: 0.9008 - val_loss: 0.0187 - val_accuracy: 0.9166\n","Epoch 25/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9032\n","Epoch 00025: val_loss improved from 0.01871 to 0.01837, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0202 - accuracy: 0.9032 - val_loss: 0.0184 - val_accuracy: 0.9112\n","Epoch 26/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9040\n","Epoch 00026: val_loss did not improve from 0.01837\n","27/27 [==============================] - 44s 2s/step - loss: 0.0199 - accuracy: 0.9040 - val_loss: 0.0195 - val_accuracy: 0.9033\n","Epoch 27/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9045\n","Epoch 00027: val_loss did not improve from 0.01837\n","27/27 [==============================] - 44s 2s/step - loss: 0.0197 - accuracy: 0.9045 - val_loss: 0.0185 - val_accuracy: 0.9134\n","Epoch 28/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9052\n","Epoch 00028: val_loss improved from 0.01837 to 0.01804, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0196 - accuracy: 0.9052 - val_loss: 0.0180 - val_accuracy: 0.9152\n","Epoch 29/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9063\n","Epoch 00029: val_loss did not improve from 0.01804\n","27/27 [==============================] - 44s 2s/step - loss: 0.0193 - accuracy: 0.9063 - val_loss: 0.0183 - val_accuracy: 0.9187\n","Epoch 30/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9054\n","Epoch 00030: val_loss improved from 0.01804 to 0.01789, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0196 - accuracy: 0.9054 - val_loss: 0.0179 - val_accuracy: 0.9156\n","Epoch 31/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9054\n","Epoch 00031: val_loss did not improve from 0.01789\n","27/27 [==============================] - 44s 2s/step - loss: 0.0195 - accuracy: 0.9054 - val_loss: 0.0181 - val_accuracy: 0.9227\n","Epoch 32/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9085\n","Epoch 00032: val_loss did not improve from 0.01789\n","27/27 [==============================] - 44s 2s/step - loss: 0.0189 - accuracy: 0.9085 - val_loss: 0.0186 - val_accuracy: 0.9227\n","Epoch 33/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9079\n","Epoch 00033: val_loss improved from 0.01789 to 0.01763, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0190 - accuracy: 0.9079 - val_loss: 0.0176 - val_accuracy: 0.9129\n","Epoch 34/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9084\n","Epoch 00034: val_loss did not improve from 0.01763\n","27/27 [==============================] - 44s 2s/step - loss: 0.0188 - accuracy: 0.9084 - val_loss: 0.0183 - val_accuracy: 0.9156\n","Epoch 35/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9100\n","Epoch 00035: val_loss improved from 0.01763 to 0.01725, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0187 - accuracy: 0.9100 - val_loss: 0.0172 - val_accuracy: 0.9207\n","Epoch 36/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9123\n","Epoch 00036: val_loss improved from 0.01725 to 0.01714, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0179 - accuracy: 0.9123 - val_loss: 0.0171 - val_accuracy: 0.9213\n","Epoch 37/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9123\n","Epoch 00037: val_loss did not improve from 0.01714\n","27/27 [==============================] - 44s 2s/step - loss: 0.0181 - accuracy: 0.9123 - val_loss: 0.0175 - val_accuracy: 0.9196\n","Epoch 38/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9129\n","Epoch 00038: val_loss improved from 0.01714 to 0.01689, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0178 - accuracy: 0.9129 - val_loss: 0.0169 - val_accuracy: 0.9180\n","Epoch 39/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9157\n","Epoch 00039: val_loss did not improve from 0.01689\n","27/27 [==============================] - 44s 2s/step - loss: 0.0173 - accuracy: 0.9157 - val_loss: 0.0171 - val_accuracy: 0.9217\n","Epoch 40/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9159\n","Epoch 00040: val_loss did not improve from 0.01689\n","27/27 [==============================] - 44s 2s/step - loss: 0.0171 - accuracy: 0.9159 - val_loss: 0.0178 - val_accuracy: 0.9238\n","Epoch 41/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9173\n","Epoch 00041: val_loss improved from 0.01689 to 0.01652, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0170 - accuracy: 0.9173 - val_loss: 0.0165 - val_accuracy: 0.9217\n","Epoch 42/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9174\n","Epoch 00042: val_loss improved from 0.01652 to 0.01640, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0169 - accuracy: 0.9174 - val_loss: 0.0164 - val_accuracy: 0.9251\n","Epoch 43/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9183\n","Epoch 00043: val_loss did not improve from 0.01640\n","27/27 [==============================] - 44s 2s/step - loss: 0.0167 - accuracy: 0.9183 - val_loss: 0.0169 - val_accuracy: 0.9267\n","Epoch 44/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9196\n","Epoch 00044: val_loss did not improve from 0.01640\n","27/27 [==============================] - 44s 2s/step - loss: 0.0164 - accuracy: 0.9196 - val_loss: 0.0164 - val_accuracy: 0.9273\n","Epoch 45/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9205\n","Epoch 00045: val_loss did not improve from 0.01640\n","27/27 [==============================] - 44s 2s/step - loss: 0.0163 - accuracy: 0.9205 - val_loss: 0.0177 - val_accuracy: 0.9290\n","Epoch 46/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9201\n","Epoch 00046: val_loss did not improve from 0.01640\n","27/27 [==============================] - 44s 2s/step - loss: 0.0164 - accuracy: 0.9201 - val_loss: 0.0168 - val_accuracy: 0.9291\n","Epoch 47/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9215\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","\n","Epoch 00047: val_loss did not improve from 0.01640\n","27/27 [==============================] - 44s 2s/step - loss: 0.0160 - accuracy: 0.9215 - val_loss: 0.0165 - val_accuracy: 0.9288\n","Epoch 48/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9239\n","Epoch 00048: val_loss improved from 0.01640 to 0.01628, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0156 - accuracy: 0.9239 - val_loss: 0.0163 - val_accuracy: 0.9287\n","Epoch 49/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9249\n","Epoch 00049: val_loss did not improve from 0.01628\n","27/27 [==============================] - 44s 2s/step - loss: 0.0153 - accuracy: 0.9249 - val_loss: 0.0164 - val_accuracy: 0.9285\n","Epoch 50/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9250\n","Epoch 00050: val_loss did not improve from 0.01628\n","27/27 [==============================] - 44s 2s/step - loss: 0.0153 - accuracy: 0.9250 - val_loss: 0.0163 - val_accuracy: 0.9285\n","Epoch 51/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9250\n","Epoch 00051: val_loss did not improve from 0.01628\n","27/27 [==============================] - 44s 2s/step - loss: 0.0152 - accuracy: 0.9250 - val_loss: 0.0163 - val_accuracy: 0.9289\n","Epoch 52/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9256\n","Epoch 00052: val_loss improved from 0.01628 to 0.01627, saving model to focal.h5\n","27/27 [==============================] - 46s 2s/step - loss: 0.0152 - accuracy: 0.9256 - val_loss: 0.0163 - val_accuracy: 0.9284\n","Epoch 53/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9255\n","Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","\n","Epoch 00053: val_loss improved from 0.01627 to 0.01621, saving model to focal.h5\n","27/27 [==============================] - 45s 2s/step - loss: 0.0152 - accuracy: 0.9255 - val_loss: 0.0162 - val_accuracy: 0.9281\n","Epoch 54/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9253\n","Epoch 00054: val_loss did not improve from 0.01621\n","27/27 [==============================] - 44s 2s/step - loss: 0.0151 - accuracy: 0.9253 - val_loss: 0.0163 - val_accuracy: 0.9292\n","Epoch 55/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9260\n","Epoch 00055: val_loss did not improve from 0.01621\n","27/27 [==============================] - 44s 2s/step - loss: 0.0151 - accuracy: 0.9260 - val_loss: 0.0162 - val_accuracy: 0.9289\n","Epoch 56/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9258\n","Epoch 00056: val_loss did not improve from 0.01621\n","27/27 [==============================] - 44s 2s/step - loss: 0.0151 - accuracy: 0.9258 - val_loss: 0.0163 - val_accuracy: 0.9293\n","Epoch 57/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9260\n","Epoch 00057: val_loss did not improve from 0.01621\n","27/27 [==============================] - 44s 2s/step - loss: 0.0151 - accuracy: 0.9260 - val_loss: 0.0163 - val_accuracy: 0.9290\n","Epoch 58/100\n","27/27 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9259\n","Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","\n","Epoch 00058: val_loss did not improve from 0.01621\n","27/27 [==============================] - 44s 2s/step - loss: 0.0151 - accuracy: 0.9259 - val_loss: 0.0162 - val_accuracy: 0.9289\n"]}],"source":["path_for_logs = '/Logs/focal-{}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\"))\n","callbacks = [\n","        tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss',min_delta=0.0001),\n","        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1),\n","        tf.keras.callbacks.ModelCheckpoint('Pranjal-U-Net-Weights.h5', verbose=1, save_best_only=True),\n","        tf.keras.callbacks.TensorBoard(log_dir=path_for_logs)\n","        ]\n","\n","results = model.fit(finalaugimg, finalaugmask/255, validation_split=0.1, batch_size=7, epochs=100, callbacks=callbacks)"]},{"cell_type":"markdown","metadata":{},"source":["#### Testing the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p_9Pe-GZDG-_"},"outputs":[],"source":["X_test = read_tiff('/test-volume.tif')\n","preds_test = model.predict(X_test, verbose=1)\n","new_pred = preds_test.reshape((30,512,512))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"elapsed":1892,"status":"ok","timestamp":1607698670548,"user":{"displayName":"Pranjal Mehul Dave","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giscu_8XllZk5OlhuruwZ1VvVa5zAHmWGkAN9rc=s64","userId":"16492860326339027474"},"user_tz":-330},"id":"OXx2dQUzB0jj","outputId":"fb511a92-4672-4d21-94c9-1839ec2f5ed9"},"outputs":[],"source":["print('At Index : {index}'.format(index = rand_num))\n","plt.subplot(121), imshow(X_test[rand_num])\n","plt.title('Test image') \n","\n","plt.subplot(122), imshow(new_pred[rand_num] > 0.5)\n","plt.title('Test label') \n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r399iOQ6bicJ"},"outputs":[],"source":["imlist = []\n","for m in new_pred:\n","    imlist.append(Image.fromarray(m>0.5))\n","\n","imlist[0].save(\"/test-labels.tif\", compression=\"tiff_deflate\", save_all=True,append_images=imlist[1:])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMJYPud1KL87hEvUh+UbeOW","collapsed_sections":[],"name":"Dave_Pranjal_Training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.9"},"vscode":{"interpreter":{"hash":"d49c3f6d6dd49f9272b571d9fad348ab55b8c6c3f691520d74ed0af1f69c3dd8"}}},"nbformat":4,"nbformat_minor":0}
